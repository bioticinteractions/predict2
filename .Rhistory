transformation = v_transformation
)
trfm <- function(df_variable, missing, min, max, zero_value, transformation){
vec_new <- sapply(df_variable, function(x) ifelse(is.na(x) == T, missing, x))
vec_new <- sapply(vec_new, function(x) ifelse(x == 0, zero_value, x)) # missing value is applied to the vector after missing transformation is applied
vec_new <- sapply(vec_new, function(x) min(max(min, x), max))
# do the data transformation via function
if (transformation == 1) {
vec_new_trans <- sapply(vec_new, function(x) ifelse(x <= 0, log(0.0001), log(x)))
} else if (transformation == 2) {
vec_new_trans <- sapply(vec_new, function(x) sqrt(x))
} else {
vec_new_trans <- vec_new
}
vec_new_trans = round(vec_new_trans, 8)
return(vec_new_trans)
}
temp_trfm_df = trfm(                                        # apply transformation
df_variable = v_data_df,
missing = v_missing,
min = v_min,
max = v_max,
zero_value = v_zero,
transformation = v_transformation
)
for (k in 1:length(data_variable)) {
# k = 11    # assign for testing purposes
v_variable = data_variable[k]                             # assign variable name k
v_variable_trfm = data_variable_trfm[k]                   # create '_trfm' variable name
v_missing = as.numeric(data_missing[k])                   # assign missing value
v_min = as.numeric(data_min[k])                           # assign minimum value
v_max = as.numeric(data_max[k])                           # assign maximum value
v_zero = as.numeric(data_zero_value[k])                   # assign zero value
v_transformation = as.numeric(data_transformation[k])     # assign transformation
v_data_df = subset(data_df, select = v_variable)          # subset specific column
# v_data_df = as.data.frame(subset(data_df, select = v_variable))   # subset specific column
# create individual vectors that contain transformed data
# assign to name variable name appended with '_trfm'
trfm <- function(df_variable, missing, min, max, zero_value, transformation){
vec_new <- sapply(df_variable, function(x) ifelse(is.na(x) == T, missing, x))
vec_new <- sapply(vec_new, function(x) ifelse(x == 0, zero_value, x)) # missing value is applied to the vector after missing transformation is applied
vec_new <- sapply(vec_new, function(x) min(max(min, x), max))
# do the data transformation via function
if (transformation == 1) {
vec_new_trans <- sapply(vec_new, function(x) ifelse(x <= 0, log(0.0001), log(x)))
} else if (transformation == 2) {
vec_new_trans <- sapply(vec_new, function(x) sqrt(x))
} else {
vec_new_trans <- vec_new
}
vec_new_trans = round(vec_new_trans, 8)
return(vec_new_trans)
}
temp_trfm_df = trfm(                                        # apply transformation
df_variable = v_data_df,
missing = v_missing,
min = v_min,
max = v_max,
zero_value = v_zero,
transformation = v_transformation
)
assign(paste0(v_variable_trfm), temp_trfm_df)               # object name to assign
# list_vec[[k]] = trfm(                                     # apply transformation
#   df_variable = v_data_df,
#   missing = v_missing,
#   min = v_min,
#   max = v_max,
#   zero_value = v_zero,
#   transformation = v_transformation
# )
writeLines(paste0('Variable transformed: ', v_variable_trfm))
} # for k loop
temp_trfm_df
v_variable_trfm
temp_trfm_df
trfm_df
library(devtools)
devtools::check()
devtools::document()
devtools::build()
# pull data from redshift
# create summary variables
# transform variables
# run predictions
# upload table to redshift
# added features
# calculate only for certain date ranges
# validation period (no need, just run for two different time periods)
####################
# load libraries ###
####################
library(RPostgreSQL)
library(data.table)
library(dplyr)
# set subfolder
folder_name = 'predict_1009'
# set directory
wd_dir = '~/cloud/google_drive/trans/sales_forecasting/' # to write and read data from the same root directory locally and ec2
# wd_dir = '~/data_r/sales_forecast/' # to write and read data from the same root directory locally and ec2
# wd_dir = '~/cloud/google_drive/trans/sales_forecasting/' # to write and read data from the same root directory locally and ec2
# read in new category mapping
# category_map = read.csv(file =  paste0(wd_dir, 'category_map.csv'), header = T, stringsAsFactors = F) # manik's list locally
# reference dataset is the july dataset
sum_br_july = fread('trans/sales_forecasting/generic_forecast/july_benchmark/sum_br_july_201720170922.csv')
sum_rk_july = fread('trans/sales_forecasting/generic_forecast/july_benchmark/sum_rk_july_201720170922.csv')
##############################################
# raw query for pulling business report data
##############################################
# set variables
date_start = '2017-09-10'
date_stop = '2017-10-09'
date_name = gsub('-', '', paste0(date_start, '_', date_stop))
sql_br = paste0("
select
t3.date as report_date,
1 as sales_month, -- this is a difference from model development where we needed month as an identifier
extract(DOY from t3.date) as sales_day_of_year,
t3.sku,
t3.child_asin,
t3.buy_box_percentage as bb_per,
t3.page_views_percentage as pv_per,
t3.units_ordered as units_ordered,
t3.units_ordered_bb as units_ordered_bb,
t3.orders_placed as orders,
t3.gross_product_sales as sales,
t3.page_views as page_views,
t3.orders_placed_bb as orders_bb,
t3.gross_product_sales_bb as sales_bb,
t3.sessions as sessions,
t3.unit_session_percentage_bb as unit_session_per_bb
--t4.product_group as category,
--t5.category_o
from etailz_ratt.reports_business_report_nrt t3
left join etailz_ratt.products_products t4 on t4.asin = t3.child_asin
--left join dash.category_map t5 on t5.category = t4.category
where 1=1
and t3.date >= '", date_start, "'
and t3.date < '", date_stop, "'
--limit 10
")
################################
# set up connection to redshift
################################
drv = dbDriver('PostgreSQL')
conn = dbConnect(
drv,
dbname = 'dw01',
host = 'redshift.twecdwh.net',
port = '5439',
user = 'dsong',
password = 'pMyt4C>k'
)
################
# execute query
################
data_br = dbGetQuery(conn, sql_br)
###############################################
# create vector of unique child asins and SKUs
# to use in subsequent SQL queries
###############################################
sql_list_asin = paste(toString(shQuote(unique(data_br$child_asin))), collapse=", ")
sql_list_sku = paste(toString(shQuote(unique(data_br$sku))), collapse=", ")
# query to get rank data and listings data
sql_rk = paste0("
select
p.sku,
p.rank,
p.listings,
p.merchantlistings,
p.fbalistings,
u.timestamp,
--date_part('month', u.timestamp) as month,
1 as month,
extract(DOY from u.timestamp) as day_of_year_rank
from etailz_ratt.gc_usa_p_info p
join etailz_ratt.gc_usa_updates u on p.update_id = u.id
where 1=1
and u.timestamp >= '", date_start, "'
and u.timestamp < '", date_stop, "'
and p.sku in (", sql_list_sku ,")
order by
u.timestamp,
p.id
--limit 10
")
# raw query
sql_ct = paste0("
select distinct
t1.asin,
t1.product_group as category,
t2.category_o
from etailz_ratt.products_products t1
left join dash.category_map t2 on t2.category = t1.product_group
where asin in (", sql_list_asin ,")
--limit 10
")
data_rk = dbGetQuery(conn, sql_rk)
data_ct = dbGetQuery(conn, sql_ct)
dbDisconnect(conn) #############
setDT(data_br)
setDT(data_rk)
setDT(data_ct)
data_br
data_rk
data_ct
###########################
# sanity check ############
###########################
table(data_br$report_date)
###########################
###########################################
# clean up data to export to sas ##########
###########################################
# merge redshift category data -- no need anymore, uploaded table to dash schema [2017-10]
data_br[data_ct, c('category', 'category_o') := mget(c('i.category', 'i.category_o')), on = c(child_asin = 'asin')]
# convert to new categories -- no need anymore, uploaded table to dash schema [2017-10]
# category_map = as.data.frame(apply(X = category_map, MARGIN = 2, FUN = function(x) trimws(x, which = 'both'))) # remove any leading and trailing white spaces
# cat_map = with(category_map, setNames(object = replace, nm = variable)) # create named vector; object = what we want to see; nm = what we want to see removed
#
# data_br$category_o = cat_map[data_br$category]
# data_br$category_o = as.character(data_br$category_o)
# table(is.na(data_br$category_o))
# table(data_br$category_o)
#
# # check to make sure category_o is not factor (0 should not show up)
# data_br$category_o = as.character(data_br$category_o)
# table(data_br$category_o)
# prepare date column: ensure datatype is date
data_br$report_date = as.Date(data_br$report_date, format = '%Y-%m-%d')
# replace blank with NA in category column
data_br$category = with(data_br, ifelse(is.na(category) | category == '', NA, category))
# merge back sku and category
# merge_back = data_br[!is.na(data_br$category), c('sku', 'category', 'category_o')]
# merge_back = merge_back[order(merge_back$sku), ]
# merge_back = unique(merge_back[, c('sku', 'category', 'category_o')])
# merge_back_dup = duplicated(merge_back$sku)
# merge_back = merge_back[merge_back_dup == F, c('sku', 'category')]
# create flag for last 15
# date_l15day = as.Date(date_stop) - 16 # for 31 day months (we can always just get 31 days; end of month/beginning of month may mean something)
# date_start_m = as.numeric(format(as.Date(date_start), format = '%m'))
# date_start_y = as.numeric(format(as.Date(date_start), format = '%Y'))
# date_l15day = as.Date(paste(date_start_y, date_start_m, 15, sep = '-'), format = '%Y-%m-%d')
# data_br$l15day = with(data_br, ifelse(report_date > date_l15day, 1, 0))
# create flag for last 7
# date_l7day = as.Date(date_stop) - 8
# date_l7day = as.Date(paste(date_start_y, date_start_m, 23, sep = '-'), format = '%Y-%m-%d')
# data_br$l7day = with(data_br, ifelse(report_date > date_l7day, 1, 0))
# clean up timestamp data from redshift
data_rk$timestamp = as.Date(substr(data_rk$timestamp, 0, 10), '%Y-%m-%d')
###############################
# check data for missing values
###############################
range(data_br$report_date)
summary_check = function(generic_df){
col_numeric = lapply(generic_df, is.numeric)
col_n_d = do.call(rbind, col_numeric)
var_col_list = row.names(col_n_d)
col_n_d = cbind.data.frame(var_col_list, col_n_d)
col_n_d$var_col_list = as.character(col_n_d$var_col_list)
row.names(col_n_d) = NULL
col_n_d = col_n_d$var_col_list[col_n_d$col_n_d == T]
# create summary df to run diagnostics
summary_df = subset(generic_df, select = col_n_d)
sum_mean = sapply(summary_df, FUN = function(x) mean(x, na.rm = T))
sum_median = sapply(summary_df, FUN = function(x) median(x, na.rm = T))
sum_na = sapply(summary_df, FUN = function(x) sum(is.na(x)))
sum_row = sapply(summary_df, FUN = function(x) length(x))
sum_bind = cbind.data.frame(
sum_mean,
sum_median,
sum_na,
sum_row
)
sum_bind_names = row.names(sum_bind)
sum_bind = cbind.data.frame(sum_bind_names, sum_bind)
sum_bind$na_ratio = with(sum_bind, sum_na / sum_row)
row.names(sum_bind) = NULL
names(sum_bind) = c(
'column',
'mean',
'median',
'count_na',
'total_rows',
'na_ratio'
)
sum_bind$column = as.character(sum_bind$column)
return(sum_bind)
}
sum_br = summary_check(data_br)
sum_rk = summary_check(data_rk)
sum_br_july
sum_br
sum_rk_july
sum_rk
###########################################################################################################
# write out data sets #####################################################################################
###########################################################################################################
data_sql_br_file = paste0(wd_dir, 'prod_mod/', folder_name, '/data_sql_br_', date_name, '.csv')
fwrite(data_br, data_sql_br_file, row.names = F)
data_sql_rk_file = paste0(wd_dir, 'prod_mod/', folder_name, '/data_sql_rk_', date_name, '.csv')
fwrite(data_rk, data_sql_rk_file, row.names = F)
data_sql_br_file;data_sql_rk_file
###########################################################################################################
###########################################################################################################
###########################################################################################################
source('~/cloud/Dropbox/R/new_package/predict2/R/func_trfm_auto_2.r')
library(data.table)
data_df = fread('temp_wd/pet_trfm_sas_cust_trfm.csv')
trfm_df = fread('temp_wd/ranks_plots_variables_pet.csv')
# data_df = fread('~/cloud/google_drive/trans/sales_forecasting/prod_mod/test_1/finaldata_r.csv', stringsAsFactors = F)
# data_df = data_df[data_df$category_o == 'Grocery', ]
# trfm_df = fread('~/cloud/google_drive/trans/sales_forecasting/grocery/ranks_plots_variables_grocery.csv', stringsAsFactors = F)
variable_col = 'variable'
min_col = 'min'
max_col = 'max'
zero_value_col = 'zero_value'
missing_col = 'missing'
transformation_col = 'transformation'
keep_col = 'keep'
list_var_cols = c(
variable_col,
min_col,
max_col,
zero_value_col,
missing_col,
transformation_col,
keep_col
)
trfm_df = subset(trfm_df, keep %in% c('y', 1), select = list_var_cols)
trfm_df
trfm_df = subset(trfm_df, keep %in% c('y', 1), select = list_var_cols)
for (i in list_var_cols){
pasted_name = paste0('data_', i)
assign(paste0(pasted_name), trfm_df[[i]])
# print(pasted_name) # for debugging
} # for i loop
data_variable_trfm = paste0(data_variable)
list_vec = vector('list', length = length(data_variable))
for (k in 1:length(data_variable)) {
# k = 11    # assign for testing purposes
v_variable = data_variable[k]                             # assign variable name k
v_variable_trfm = data_variable_trfm[k]                   # create '_trfm' variable name
v_missing = as.numeric(data_missing[k])                   # assign missing value
v_min = as.numeric(data_min[k])                           # assign minimum value
v_max = as.numeric(data_max[k])                           # assign maximum value
v_zero = as.numeric(data_zero_value[k])                   # assign zero value
v_transformation = as.numeric(data_transformation[k])     # assign transformation
v_data_df = subset(data_df, select = v_variable)          # subset specific column
# v_data_df = as.data.frame(subset(data_df, select = v_variable))   # subset specific column
# create individual vectors that contain transformed data
# assign to name variable name appended with '_trfm'
trfm <- function(df_variable, missing, min, max, zero_value, transformation){
vec_new <- sapply(df_variable, function(x) ifelse(is.na(x) == T, missing, x))
vec_new <- sapply(vec_new, function(x) ifelse(x == 0, zero_value, x)) # missing value is applied to the vector after missing transformation is applied
vec_new <- sapply(vec_new, function(x) min(max(min, x), max))
# do the data transformation via function
if (transformation == 1) {
vec_new_trans <- sapply(vec_new, function(x) ifelse(x <= 0, log(0.0001), log(x)))
} else if (transformation == 2) {
vec_new_trans <- sapply(vec_new, function(x) sqrt(x))
} else {
vec_new_trans <- vec_new
}
vec_new_trans = round(vec_new_trans, 8)
return(vec_new_trans)
}
temp_trfm_df = trfm(                                        # apply transformation
df_variable = v_data_df,
missing = v_missing,
min = v_min,
max = v_max,
zero_value = v_zero,
transformation = v_transformation
)
assign(paste0(v_variable_trfm), temp_trfm_df)               # object name to assign
# list_vec[[k]] = trfm(                                     # apply transformation
#   df_variable = v_data_df,
#   missing = v_missing,
#   min = v_min,
#   max = v_max,
#   zero_value = v_zero,
#   transformation = v_transformation
# )
writeLines(paste0('Variable transformed: ', v_variable_trfm))
} # for k loop
writeLines(paste0('Variable transformed: ', v_variable_trfm))
data_variable_trfm
as.data.frame(sapply(data_variable_trfm, function(x) get(paste0(x))))
get(paste0(x))
data_variable_trfm
temp_df = as.data.frame(sapply(data_variable_trfm, function(x) get(paste0(x))))
temp_df
temp_df
temp_df
v_variable_trfm
temp_trfm_df
data_df = fread('~/cloud/google_drive/trans/sales_forecasting/prod_mod/test_1/finaldata_r.csv', stringsAsFactors = F)
data_df = data_df[data_df$category_o == 'Grocery', ]
trfm_df = fread('~/cloud/google_drive/trans/sales_forecasting/grocery/ranks_plots_variables_grocery.csv', stringsAsFactors = F)
variable_col = 'variable'
min_col = 'min'
max_col = 'max'
zero_value_col = 'zero_value'
missing_col = 'missing'
transformation_col = 'transformation'
keep_col = 'keep'
# create vectors for columns needed in trfm()
# the vector is purposely a list of objects rather than strings
list_var_cols = c(
variable_col,
min_col,
max_col,
zero_value_col,
missing_col,
transformation_col,
keep_col
)
# subset transformation data, only keep those with keep == 'yes'
# using 'subset' so that it can accommodate both datatable and dataframes
trfm_df = subset(trfm_df, keep %in% c('y', 1), select = list_var_cols)
# trfm_df = subset(
#   trfm_df,
#   keep %in% c('y', 1),
#   select = c(
#     variable_col,
#     min_col,
#     max_col,
#     zero_value_col,
#     missing_col,
#     transformation_col,
#     keep_col
#   )
# ) # using subset so that it can accommodate both datatable and dataframes
# assign data for each item in list_var_cols
for (i in list_var_cols){
pasted_name = paste0('data_', i)
assign(paste0(pasted_name), trfm_df[[i]])
# print(pasted_name) # for debugging
} # for i loop
# 'data_variable' is a reference to the variable column
# originally wanted to have fixed custom column names (.*_trfm)
data_variable_trfm = paste0(data_variable)
list_vec = vector('list', length = length(data_variable))
# use trfm() for each of the variables
for (k in 1:length(data_variable)) {
# k = 11    # assign for testing purposes
v_variable = data_variable[k]                             # assign variable name k
v_variable_trfm = data_variable_trfm[k]                   # create '_trfm' variable name
v_missing = as.numeric(data_missing[k])                   # assign missing value
v_min = as.numeric(data_min[k])                           # assign minimum value
v_max = as.numeric(data_max[k])                           # assign maximum value
v_zero = as.numeric(data_zero_value[k])                   # assign zero value
v_transformation = as.numeric(data_transformation[k])     # assign transformation
v_data_df = subset(data_df, select = v_variable)          # subset specific column
# create individual vectors that contain transformed data
# assign to name variable name appended with '_trfm'
trfm <- function(df_variable, missing, min, max, zero_value, transformation){
vec_new <- sapply(df_variable, function(x) ifelse(is.na(x) == T, missing, x))
vec_new <- sapply(vec_new, function(x) ifelse(x == 0, zero_value, x)) # missing value is applied to the vector after missing transformation is applied
vec_new <- sapply(vec_new, function(x) min(max(min, x), max))
# do the data transformation via function
if (transformation == 1) {
vec_new_trans <- sapply(vec_new, function(x) ifelse(x <= 0, log(0.0001), log(x)))
} else if (transformation == 2) {
vec_new_trans <- sapply(vec_new, function(x) sqrt(x))
} else {
vec_new_trans <- vec_new
}
vec_new_trans = round(vec_new_trans, 8)
return(vec_new_trans)
}
# apply transformation
temp_trfm_df = trfm(
df_variable = v_data_df,
missing = v_missing,
min = v_min,
max = v_max,
zero_value = v_zero,
transformation = v_transformation
)
# assign transformed dataframe to variable name
assign(paste0(v_variable_trfm), temp_trfm_df)
# print out the column transformed
writeLines(paste0('Variable transformed: ', v_variable_trfm))
} # for k loop
# get dataframe object from vector containing object names, then combine into dataframe
temp_df = as.data.frame(sapply(data_variable_trfm, function(x) get(paste0(x))))
temp_df
df_variable
library(devtools)
devtools::check()
library(devtools)
devtools::check()
devtools::document()
devtools::build()
remove.packages("predict2")
install.packages('../predict2_0.1.tar.gz', repos = NULL, type = 'source')
library(devtools)
devtools::check()
library(devtools)
devtools::check()
library(devtools)
devtools::check()
devtools::document()
devtools::build()
remove.packages("predict2")
install.packages('../predict2_0.1.tar.gz', repos = NULL, type = 'source')
devtools::check()
library(devtools)
devtools::check()
devtools::document()
devtools::build()
